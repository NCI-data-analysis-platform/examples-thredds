{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download a single file from remote data services\n",
    "\n",
    "* Query CSW endpoints to fetch the thredds service\n",
    "* download data using the following utilities\n",
    "    - requests.get\n",
    "    - urllib\n",
    "    - wget\n",
    "    - xarray.open_dataset()\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Authors: NCI Virtual Research Environment Team\n",
    "- Keywords: CSW, geonetwork, data query, search\n",
    "- Create Date: 2020-Jun\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import rasterio\n",
    "import requests\n",
    "from owslib import fes\n",
    "from owslib.fes import PropertyIsEqualTo, PropertyIsLike, BBox\n",
    "from owslib.csw import CatalogueServiceWeb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csw_records(csw, filter_list, pagesize=10, maxrecords=500):\n",
    "    \"\"\"Iterate `maxrecords`/`pagesize` times until the requested value in\n",
    "    `maxrecords` is reached.\n",
    "    \"\"\"\n",
    "    from owslib.fes import SortBy, SortProperty\n",
    "\n",
    "    # Iterate over sorted results.\n",
    "    sortby = SortBy([SortProperty(\"dc:title\")])\n",
    "    csw_records = {}\n",
    "    startposition = 0\n",
    "    nextrecord = getattr(csw, \"results\", 1)\n",
    "    while nextrecord != 0:\n",
    "        csw.getrecords2(\n",
    "            constraints=filter_list,\n",
    "            startposition=startposition,\n",
    "            maxrecords=pagesize,\n",
    "            sortby=sortby,\n",
    "        )\n",
    "        csw_records.update(csw.records)\n",
    "        if csw.results[\"nextrecord\"] == 0:\n",
    "            break\n",
    "        startposition += pagesize + 1  # Last one is included.\n",
    "        if startposition >= maxrecords:\n",
    "            break\n",
    "    csw.records.update(csw_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from owslib import fes\n",
    "from owslib.fes import PropertyIsEqualTo, PropertyIsLike, BBox\n",
    "\n",
    "# Region: Australia.\n",
    "min_lon, max_lon = 110, 160\n",
    "min_lat, max_lat = -45, -5\n",
    "\n",
    "bbox = [min_lon, min_lat, max_lon, max_lat]\n",
    "\n",
    "# Sea surface temperature CF names.\n",
    "words = [\n",
    "    \"dataset\",\n",
    "    \"geophysics\",\n",
    "    \"GA\"\n",
    "]\n",
    "\n",
    "kw = dict(wildCard=\"*\", escapeChar=\"\\\\\", singleChar=\"?\", propertyname=\"apiso:AnyText\")\n",
    "\n",
    "or_filt = fes.And([fes.PropertyIsEqualTo('csw:AnyText',f'{val}') for val in words])\n",
    "\n",
    "bbox = fes.BBox(bbox)\n",
    "\n",
    "filter_list = [\n",
    "    fes.And(\n",
    "        [\n",
    "            bbox,  # bounding box\n",
    "            or_filt,  # or conditions (searching words)\n",
    "        ]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28 records.\n",
      "\n",
      "[radmap v3 2015 ratio uranium over thorium grid]\n",
      "221dcfd8-04fa-5083-e053-10a3070a64e3\n",
      "\n",
      "[radmap v3 2015 ratio uranium squared over thorium grid]\n",
      "221dcfd8-04fb-5083-e053-10a3070a64e3\n",
      "\n",
      "[radmap v3 2015 unfiltered pct potassium grid]\n",
      "221dcfd8-04fc-5083-e053-10a3070a64e3\n",
      "\n",
      "[radmap v3 2015 unfiltered ppm thorium grid]\n",
      "221dcfd8-04fd-5083-e053-10a3070a64e3\n",
      "\n",
      "[radmap v3 2015 unfiltered ppm uranium grid]\n",
      "221dcfd8-04fe-5083-e053-10a3070a64e3\n",
      "\n",
      "[radmap v3 2015 unfiltered terrestrial dose rate grid]\n",
      "221dcfd8-04ff-5083-e053-10a3070a64e3\n",
      "\n",
      "[Total Magnetic Intensity (TMI) Grid of Australia 2015 - sixth edition]\n",
      "221dcfd8-04ee-5083-e053-10a3070a64e3\n",
      "\n",
      "[Total Magnetic Intensity (TMI) Grid of Australia with Variable Reduction to Pole (VRTP) - sixth edition]\n",
      "221dcfd8-04ef-5083-e053-10a3070a64e3\n",
      "\n",
      "[Australian National Geophysical Data Collection]\n",
      "0a83ee36-d332-4669-a9fc-dfa7cec5c703\n",
      "\n",
      "[Bouguer Gravity Anomaly Grid of Onshore Australia 2016]\n",
      "d82dff4d-c1c6-4fd7-83c5-fc1bf39be0d7\n",
      "\n",
      "[Broadband and long-period MT survey acquired along the southern part of the GOMA (Gawler Craton, Officer Basin, Musgrave Province, Amadeus Basin) deep seismic reflection transect (GA08-OM1) from Tarcoola to near Coober Pedy in South Australia (beside the Adelaide-Darwin railway line), collected in December 2008]\n",
      "f5652_7712_4276_8823\n",
      "\n",
      "[Geophysical Data Collection - Airborne Geophysics]\n",
      "ddeb0fc4-32e3-4913-80f2-f4249b17a925\n",
      "\n",
      "[Geophysical Data Collection - ground gravity]\n",
      "c6b58f54-102c-19e9-e044-00144fdd4fa6\n",
      "\n",
      "[Global Navigation Satellite System (GNSS) Data Archive]\n",
      "f3933_4628_9275_8464\n",
      "\n",
      "[Intertidal Extents Model Collection]\n",
      "42b76130-9055-45ab-b34f-2b4ddef34cca\n",
      "\n",
      "[Isostatic Residual Gravity Anomaly Grid of Onshore Australia - 2011]\n",
      "dbcc0c59-81e6-4eed-e044-00144fdd4fa6\n",
      "\n",
      "[Isostatic Residual Gravity Anomaly Grid of Onshore Australia 2016]\n",
      "cac517b6-971d-4d21-8bf2-eb08c75fc465\n",
      "\n",
      "[Landcover 25 - Water (Water Observations from Space - WOfS)]\n",
      "fafc45be-74f2-6b60-e044-00144fdd4fa6\n",
      "\n",
      "[Magnetotelluric data acquired in the Southern Flinders Rangers, 2009.]\n",
      "f6255_3737_4382_1461\n",
      "\n",
      "[MH370 Search Phase 1 Raw and Processed datasets]\n",
      "19fc382c-6317-48d6-b174-4b4664fb10cd\n",
      "\n",
      "[Models of Land and Water Dynamics from Space Data Collection]\n",
      "f3197_8386_1440_4330\n",
      "\n",
      "[Onshore Bouguer offshore Freeair gravity geodetic June 2009]\n",
      "221dcfd8-04f1-5083-e053-10a3070a64e3\n",
      "\n",
      "[Onshore geodetic Spherical Cap Bouguer June 2009]\n",
      "221dcfd8-04f2-5083-e053-10a3070a64e3\n",
      "\n",
      "[radmap v3 2015 filtered pct potassium grid]\n",
      "221dcfd8-04f4-5083-e053-10a3070a64e3\n",
      "\n",
      "[radmap v3 2015 filtered ppm thorium grid]\n",
      "221dcfd8-04f5-5083-e053-10a3070a64e3\n",
      "\n",
      "[radmap v3 2015 filtered ppm uranium grid]\n",
      "221dcfd8-04f6-5083-e053-10a3070a64e3\n",
      "\n",
      "[radmap v3 2015 filtered terrestrial dose rate grid]\n",
      "221dcfd8-04f7-5083-e053-10a3070a64e3\n",
      "\n",
      "[radmap v3 2015 ratio thorium over potassium grid]\n",
      "221dcfd8-04f8-5083-e053-10a3070a64e3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_csw_records(csw, filter_list, pagesize=10, maxrecords=1000)\n",
    "\n",
    "records = \"\\n\".join(csw.records.keys())\n",
    "print(\"Found {} records.\\n\".format(len(csw.records.keys())))\n",
    "for key, value in list(csw.records.items()):\n",
    "    print(u\"[{}]\\n{}\\n\".format(value.title, key))\n",
    "    \n",
    "record_list = [record for record in records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_netcdf_urls(self, dataset_dict_generator):\n",
    "        '''\n",
    "        Generator to yield flattened dicts containing information for any netCDF distributions (file or OPeNDAP URL, file by preference)\n",
    "        @param dataset_dict_generator: Generator yeilding dict objects containing information about each record including distributions\n",
    "        '''\n",
    "        for record_dict in dataset_dict_generator:\n",
    "            distribution_dict = None\n",
    "            for file_distribution in record_dict['distributions']:\n",
    "                if 'file' in file_distribution['protocol'].lower():\n",
    "                    match = re.match('(^file://)*(.*\\.nc)$', file_distribution['url'])\n",
    "                    try:\n",
    "                        file_distribution['url'] = match.group(2) # Ignore any leading \"file://\"\n",
    "                        if os.path.isfile(file_distribution['url']) and netCDF4.Dataset(file_distribution['url']): # Test for valid netCDF file\n",
    "                            #logger.debug('file found')\n",
    "                            distribution_dict = file_distribution\n",
    "                            break\n",
    "                    except:\n",
    "                        logger.warning('Unable to open netCDF file {}'.format(file_distribution['url']))\n",
    "                    \n",
    "            if not distribution_dict:\n",
    "                # Check for valid OPeNDAP endpoint if no valid file found\n",
    "                for opendap_distribution in record_dict['distributions']:\n",
    "                    if 'opendap' in opendap_distribution['protocol'].lower():\n",
    "                        match = re.match('(.*\\.nc)(\\.html)*$', opendap_distribution['url'])\n",
    "                        try:\n",
    "                            opendap_distribution['url'] = match.group(1) # Ignore any trailing \".html\"\n",
    "                            #if netCDF4.Dataset(opendap_distribution['url']): # Test for valid OPeNDAP endpoint\n",
    "                            #TODO: Make a better test for a valid OPeNDAP URL\n",
    "                            response = requests.get(opendap_distribution['url'])\n",
    "                            if response.status_code == 400: # Test for valid OPeNDAP endpoint\n",
    "                                distribution_dict = opendap_distribution\n",
    "                                break\n",
    "                        except:\n",
    "                            logger.warning('Unable to open OPeNDAP URL {}'.format(opendap_distribution['url']))\n",
    "            \n",
    "            if distribution_dict:\n",
    "                yield self.flatten_distribution_dict(record_dict, distribution_dict)\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_netcdf_urls() missing 1 required positional argument: 'dataset_dict_generator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-65258d0188c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m netcdf_list = [distribution['url']\n\u001b[0;32m----> 2\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mdistribution\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_netcdf_urls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m             ]\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} NetCDF distributions found'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetcdf_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_netcdf_urls() missing 1 required positional argument: 'dataset_dict_generator'"
     ]
    }
   ],
   "source": [
    "netcdf_list = [distribution['url']\n",
    "            for distribution in get_netcdf_urls(record_list)\n",
    "            ]\n",
    "\n",
    "print('{} NetCDF distributions found'.format(len(netcdf_list)))\n",
    "    \n",
    "return netcdf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(in_filename, out_filename):\n",
    "    if not os.path.exists(out_filename):\n",
    "        print(\"Downloading\", in_filename)\n",
    "        response = requests.get(in_filename)\n",
    "        with open(out_filename, 'wb') as f:\n",
    "            f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://dapds00.nci.org.au/thredds/fileServer/rr2/national_geophysical_compilations/IR_gravity_anomaly_Australia_V1/IR_gravity_anomaly_Australia_V1.nc\n"
     ]
    }
   ],
   "source": [
    "url = 'http://dapds00.nci.org.au/thredds/fileServer/rr2/national_geophysical_compilations/IR_gravity_anomaly_Australia_V1/IR_gravity_anomaly_Australia_V1.nc'\n",
    "\n",
    "download_file(url, 'IR.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('IR1.nc', <http.client.HTTPMessage at 0x1247d1278>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib import request\n",
    "request.urlretrieve(url,'IR1.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-20 21:28:24--  http://dapds00.nci.org.au/thredds/fileServer/rr2/national_geophysical_compilations/IR_gravity_anomaly_Australia_V1/IR_gravity_anomaly_Australia_V1.nc\n",
      "Resolving dapds00.nci.org.au... 130.56.243.202\n",
      "Connecting to dapds00.nci.org.au|130.56.243.202|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 30489513 (29M) [application/x-netcdf]\n",
      "Saving to: 'IR_gravity_anomaly_Australia_V1.nc'\n",
      "\n",
      "IR_gravity_anomaly_ 100%[===================>]  29.08M  1.32MB/s    in 22s     \n",
      "\n",
      "2020-05-20 21:28:46 (1.31 MB/s) - 'IR_gravity_anomaly_Australia_V1.nc' saved [30489513/30489513]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget $url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
